{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1becff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xiangzairan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/xiangzairan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/xiangzairan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xiangzairan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/xiangzairan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/xiangzairan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from runner import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f39dae",
   "metadata": {},
   "source": [
    "# Coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24a21e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "get_idf\n",
      "getting predictions\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for nyt are (0.6214973540383447, 0.48048124610816956)\n"
     ]
    }
   ],
   "source": [
    "tfidf_runner_nyt = TFIDF_runner('nyt', 'coarse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2d415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "get_idf\n",
      "getting predictions\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for 20news are (0.4450955693082863, 0.49520294329382036)\n"
     ]
    }
   ],
   "source": [
    "tfidf_runner_nyt = TFIDF_runner('20news', 'coarse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57b44a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "getting the vector for each word...\n",
      "getting the vector for each document...\n",
      "getting the prediction...\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for nyt are (0.933026806627917, 0.7041593244355895)\n"
     ]
    }
   ],
   "source": [
    "w2v_runner_nyt = W2V_Runner('nyt', 'coarse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f849a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "getting the vector for each word...\n",
      "getting the vector for each document...\n",
      "getting the prediction...\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for 20news are (0.6228709129744235, 0.48250388205407535)\n"
     ]
    }
   ],
   "source": [
    "w2v_runner_nyt = W2V_Runner('20news', 'coarse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a046dfc",
   "metadata": {},
   "source": [
    "### F1 scores before updating the tokenization func\n",
    "- TFIDF nyt coarse: (0.6056215841068795, 0.4616727216619872)\n",
    "- TFIDF 20news coarse:  (0.4335396242948683, 0.4724983248391604)\n",
    "\n",
    "- Word2Vec nyt coarse: (0.8374251756745034, 0.4204646418824273)\n",
    "- Word2Vec 20news coarse: (0.4076345911605236, 0.2902743588340004)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2edaa4",
   "metadata": {},
   "source": [
    "### TFiDF: updated tokenization func:\n",
    "- nyt coarse: (0.6214973540383447, 0.48048124610816956) / （0.65 0.58): -0.03，-0.1\n",
    "- 20news coarse: (0.4450955693082863, 0.49520294329382036) / （0.49， 0.48）: -0.05, +0.01\n",
    "\n",
    "### Word2Vec: updated tokenization func:\n",
    "- nyt coarse: (0.933026806627917, 0.7041593244355895) / (0.92 0.83): +0.01, -0.13\n",
    "- 20news coarse: (0.6228709129744235, 0.48250388205407535) / (0.51, 0.45): +0.12, +0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8051425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NYT_coarse_Micro</th>\n",
       "      <th>NYT_coarse_Macro</th>\n",
       "      <th>NYT_fine_Micro</th>\n",
       "      <th>NYT_fine_Macro</th>\n",
       "      <th>20_coarse_Micro</th>\n",
       "      <th>20_coarse_Macro</th>\n",
       "      <th>20_fine_Micro</th>\n",
       "      <th>20_fine_Macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TFIDF</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NYT_coarse_Micro  NYT_coarse_Macro  NYT_fine_Micro  NYT_fine_Macro  \\\n",
       "Model                                                                          \n",
       "TFIDF                 0.62              0.48            0.52            0.56   \n",
       "Word2Vec              0.93              0.70            0.18            0.12   \n",
       "\n",
       "          20_coarse_Micro  20_coarse_Macro  20_fine_Micro  20_fine_Macro  \n",
       "Model                                                                     \n",
       "TFIDF                0.45             0.50           0.49           0.52  \n",
       "Word2Vec             0.62             0.48           0.26           0.16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['TFIDF', 0.62, 0.48, 0.52, 0.56,\n",
    "        0.45, 0.50, 0.49, 0.52], \n",
    "       ['Word2Vec', 0.93, 0.70, 0.18, 0.12, \n",
    "        0.62, 0.48, 0.26, 0.16]\n",
    "       ]\n",
    "\n",
    "df_result = pd.DataFrame(data, columns = ['Model','NYT_coarse_Micro','NYT_coarse_Macro','NYT_fine_Micro','NYT_fine_Macro', \n",
    "     '20_coarse_Micro','20_coarse_Macro','20_fine_Micro','20_fine_Macro']).set_index('Model')\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0f65641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2e04a_row0_col3, #T_2e04a_row0_col5, #T_2e04a_row1_col0, #T_2e04a_row1_col4, #T_2e04a_row1_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "#T_2e04a_row1_col2, #T_2e04a_row1_col3 {\n",
       "  background: #ff33aa;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2e04a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2e04a_level0_col0\" class=\"col_heading level0 col0\" >NYT_coarse_Micro</th>\n",
       "      <th id=\"T_2e04a_level0_col1\" class=\"col_heading level0 col1\" >NYT_coarse_Macro</th>\n",
       "      <th id=\"T_2e04a_level0_col2\" class=\"col_heading level0 col2\" >NYT_fine_Micro</th>\n",
       "      <th id=\"T_2e04a_level0_col3\" class=\"col_heading level0 col3\" >NYT_fine_Macro</th>\n",
       "      <th id=\"T_2e04a_level0_col4\" class=\"col_heading level0 col4\" >20_coarse_Micro</th>\n",
       "      <th id=\"T_2e04a_level0_col5\" class=\"col_heading level0 col5\" >20_coarse_Macro</th>\n",
       "      <th id=\"T_2e04a_level0_col6\" class=\"col_heading level0 col6\" >20_fine_Micro</th>\n",
       "      <th id=\"T_2e04a_level0_col7\" class=\"col_heading level0 col7\" >20_fine_Macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2e04a_level0_row0\" class=\"row_heading level0 row0\" >TFIDF</th>\n",
       "      <td id=\"T_2e04a_row0_col0\" class=\"data row0 col0\" >-0.028503</td>\n",
       "      <td id=\"T_2e04a_row0_col1\" class=\"data row0 col1\" >-0.099519</td>\n",
       "      <td id=\"T_2e04a_row0_col2\" class=\"data row0 col2\" >-0.035839</td>\n",
       "      <td id=\"T_2e04a_row0_col3\" class=\"data row0 col3\" >0.017696</td>\n",
       "      <td id=\"T_2e04a_row0_col4\" class=\"data row0 col4\" >-0.044904</td>\n",
       "      <td id=\"T_2e04a_row0_col5\" class=\"data row0 col5\" >0.015203</td>\n",
       "      <td id=\"T_2e04a_row0_col6\" class=\"data row0 col6\" >-0.044267</td>\n",
       "      <td id=\"T_2e04a_row0_col7\" class=\"data row0 col7\" >-0.002707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e04a_level0_row1\" class=\"row_heading level0 row1\" >Word2Vec</th>\n",
       "      <td id=\"T_2e04a_row1_col0\" class=\"data row1 col0\" >0.013027</td>\n",
       "      <td id=\"T_2e04a_row1_col1\" class=\"data row1 col1\" >-0.125841</td>\n",
       "      <td id=\"T_2e04a_row1_col2\" class=\"data row1 col2\" >-0.510508</td>\n",
       "      <td id=\"T_2e04a_row1_col3\" class=\"data row1 col3\" >-0.352818</td>\n",
       "      <td id=\"T_2e04a_row1_col4\" class=\"data row1 col4\" >0.112871</td>\n",
       "      <td id=\"T_2e04a_row1_col5\" class=\"data row1 col5\" >0.032504</td>\n",
       "      <td id=\"T_2e04a_row1_col6\" class=\"data row1 col6\" >-0.066787</td>\n",
       "      <td id=\"T_2e04a_row1_col7\" class=\"data row1 col7\" >-0.169441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff1a72a4430>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_difference = [['TFIDF', 0.6214973540383447-0.65, 0.48048124610816956-0.58, \n",
    "                    0.4450955693082863-0.49, 0.49520294329382036-0.48,\n",
    "                    0.5241606662618201-0.56, 0.5576955603925752-0.54,\n",
    "                    0.48573306314694126-0.53, 0.5172928697291572-0.52\n",
    "                   ], \n",
    "                   ['Word2Vec', 0.933026806627917-0.92, 0.7041593244355895-0.83,\n",
    "                    0.6228709129744235-0.51, 0.48250388205407535-0.45, \n",
    "                    0.1794916283508285-0.69, 0.11718246329492527-0.47, \n",
    "                    0.26321266224875406-0.33, 0.16055863406622267-0.33]\n",
    "                  ]\n",
    "\n",
    "df_difference = pd.DataFrame(data_difference, columns = \n",
    "                             ['Model','NYT_coarse_Micro','NYT_coarse_Macro',\n",
    "                              '20_coarse_Micro','20_coarse_Macro',\n",
    "                              'NYT_fine_Micro','NYT_fine_Macro',\n",
    "                              '20_fine_Micro','20_fine_Macro']).set_index('Model')\n",
    "\n",
    "df_difference.style.apply(lambda x: [\"background: yellow\" if v > 0 else \"\" for v in x], axis = 1).apply(lambda x: [\"background: #ff33aa\" if v < -0.2 else \"\" for v in x], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae5cf4",
   "metadata": {},
   "source": [
    "# Fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86c905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "get_idf\n",
      "getting predictions\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for nyt are (0.5241606662618201, 0.5576955603925752)\n"
     ]
    }
   ],
   "source": [
    "tfidf_runner_nyt = TFIDF_runner('nyt', 'fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70ccc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "get_idf\n",
      "getting predictions\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for 20news are (0.48573306314694126, 0.5172928697291572)\n"
     ]
    }
   ],
   "source": [
    "tfidf_runner_nyt = TFIDF_runner('20news', 'fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433e6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "getting the vector for each word...\n",
      "getting the vector for each document...\n",
      "getting the prediction...\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for nyt are (0.1794916283508285, 0.11718246329492527)\n"
     ]
    }
   ],
   "source": [
    "w2v_runner_nyt = W2V_Runner('nyt', 'fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91424e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing documents...\n",
      "getting the vector for each word...\n",
      "getting the vector for each document...\n",
      "getting the prediction...\n",
      "calculating accuracy\n",
      "micro and macro f1 scores for 20news are (0.26321266224875406, 0.16055863406622267)\n"
     ]
    }
   ],
   "source": [
    "w2v_runner_nyt = W2V_Runner('20news', 'fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014f5d3",
   "metadata": {},
   "source": [
    "### F1 scores before updating the tokenization func\n",
    "\n",
    "- TFiDF nyt fine: (0.523467, 0.584642)\n",
    "- TFiDF 20news fine:  (0.475163, 0.522269)\n",
    "- Word2Vec nyt fine: (0.297562,\t0.124704)\n",
    "- Word2Vec 20news fine: (0.162660, 0.096024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4a2f08",
   "metadata": {},
   "source": [
    "### TFiDF: updated tokenization func:\n",
    "- nyt fine: (0.5241606662618201, 0.5576955603925752) / （0.56 0.54): -0.04, -0.01\n",
    "- 20news fine: (0.48573306314694126, 0.5172928697291572) / （0.53， 0.52）: -0.05, -0.003\n",
    "\n",
    "### Word2Vec: updated tokenization func (without stemmer)\n",
    "- nyt fine: (0.1794916283508285, 0.11718246329492527) / (0.69 0.47):\n",
    "- 20news fine: (0.26321266224875406, 0.16055863406622267) / (0.33, 0.33):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3e3af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
